{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "external-elephant",
   "metadata": {},
   "source": [
    "## This notebook takes takes the sketches from photodraw2x2 and uploads it to amazon S3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "absolute-ranch",
   "metadata": {},
   "source": [
    "### Import libraries, add helper functions, and set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "diagnostic-singer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import botocore\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brilliant-management",
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_files(path, ext='png'):\n",
    "    result = [y for x in os.walk(path) for y in glob(os.path.join(x[0], '*.%s' % ext))]\n",
    "    return result\n",
    "\n",
    "## helper to speed things up by not uploading images if they already exist, can be overriden \n",
    "def check_exists(s3, bucket_name, stim_name):\n",
    "    try:\n",
    "        s3.Object(bucket_name,stim_name).load()    \n",
    "        return True\n",
    "    except botocore.exceptions.ClientError as e:    \n",
    "        if (e.response['Error']['Code'] == \"404\"):\n",
    "            print('The object does not exist.')\n",
    "            return False\n",
    "        else:\n",
    "            print('Something else has gone wrong with {}'.format(stim_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "chicken-mailman",
   "metadata": {},
   "outputs": [],
   "source": [
    "proj_dir = os.path.abspath('..')\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "exp_dir = os.path.abspath(os.path.join(proj_dir,'experiments'))\n",
    "sketch_dir = os.path.abspath(os.path.join(proj_dir,'sketches'))\n",
    "gallery_dir = os.path.abspath(os.path.join(proj_dir,'gallery'))\n",
    "feature_dir = os.path.abspath(os.path.join(proj_dir,'features'))\n",
    "stims_dir = os.path.abspath(os.path.join(proj_dir,'stimuli','photodraw32_stims_agglomerate'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "postal-thought",
   "metadata": {},
   "source": [
    "### Create metadata for loading into S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-tract",
   "metadata": {},
   "outputs": [],
   "source": [
    "destinationFiles = list_files(os.path.join(sketch_dir, 'photodraw2x2'), 'png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "harmful-gregory",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "photodraw32_s3_sketches_metadata = pd.DataFrame(columns = ['gameID', \n",
    "                                                           'condition', \n",
    "                                                           'category',\n",
    "                                                           'image_id',\n",
    "                                                           'goal',\n",
    "                                                           'filepath',\n",
    "                                                           'filename',\n",
    "                                                           's3_url'])\n",
    "for file in destinationFiles:\n",
    "    gameID, trialNum, condition, rest = file.split('\\\\')[-1].split('.')[0].split('_',3)\n",
    "    if condition == 'photo':\n",
    "        category, image, ID, goal = rest.rsplit('_', 3)\n",
    "        image_id = image + '_' + ID\n",
    "    else:\n",
    "        category, image_id, goal = rest.rsplit('_', 2)\n",
    "    filepath = \"..\\\\\" + file.split('\\\\', 2)[-1]\n",
    "    filename = os.path.split(file)[1]\n",
    "    s3_url = \"https://photodraw32.s3.amazonaws.com/\" + filename\n",
    "    photodraw32_s3_sketches_metadata = photodraw32_s3_sketches_metadata.append({'gameID' : gameID, \n",
    "                                                                                'condition' : condition, \n",
    "                                                                                'category' : category, \n",
    "                                                                                'image_id' : image_id, \n",
    "                                                                                'goal' : goal,\n",
    "                                                                                'filepath' : filepath,\n",
    "                                                                                'filename' : filename,\n",
    "                                                                                's3_url' : s3_url},\n",
    "                                                                               ignore_index = True)\n",
    "\n",
    "photodraw32_s3_sketches_metadata.to_csv('photodraw32_s3_sketches_metadata.csv', index=False)\n",
    "photodraw32_s3_sketches_metadata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-candy",
   "metadata": {},
   "source": [
    "### Load into S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "occupied-flash",
   "metadata": {},
   "outputs": [],
   "source": [
    "photodraw_testing_data = {'bucket_name': 'photodraw-testing',\n",
    "                          'path_to_stim': 'images',\n",
    "                          'full_stim_paths': '---------',  # use list_files(path_to_stim)\n",
    "                          'stim_name': '-----------'} # use os.path.split(path_to_file)[-1]\n",
    "\n",
    "df = pd.read_csv('photodraw32_s3_sketches_metadata.csv')\n",
    "photodraw32_data = {'bucket_name': 'photodraw32',\n",
    "                    'path_to_stim': 'photodraw32_sketches',\n",
    "                    'full_stim_paths': df.filepath.values,\n",
    "                    's3_stim_names': df.filename.values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "experimental-nudist",
   "metadata": {},
   "outputs": [],
   "source": [
    "## set up paths, etc.\n",
    "bucket_name = photodraw32_data['bucket_name'] ## which S3 bucket to upload to \n",
    "path_to_stim = photodraw32_data['path_to_stim']\n",
    "full_stim_paths = photodraw32_data['full_stim_paths']\n",
    "stim_names = photodraw32_data['s3_stim_names']\n",
    "print('We have {} images to upload.'.format(len(full_stim_paths)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "close-concert",
   "metadata": {},
   "outputs": [],
   "source": [
    "## tell user some useful information\n",
    "print('Path to stimuli is : {}'.format(path_to_stim))\n",
    "print('Uploading to this bucket: {}'.format(bucket_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "significant-moisture",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "reallyRun = 0\n",
    "if reallyRun: \n",
    "\n",
    "    ## establish connection to s3 \n",
    "    s3 = boto3.resource('s3')\n",
    "\n",
    "    ## create a bucket with the appropriate bucket name\n",
    "    try: \n",
    "        b = s3.create_bucket(Bucket=bucket_name) \n",
    "        print('Created new bucket.')\n",
    "    except:\n",
    "        b = s3.Bucket(bucket_name)\n",
    "        print('Bucket already exists.')\n",
    "\n",
    "    ## do we want to overwrite files on s3?\n",
    "    overwrite = False\n",
    "    \n",
    "    ## set bucket and objects to public\n",
    "    b.Acl().put(ACL='public-read') ## sets bucket to public\n",
    "\n",
    "    ## now let's loop through stim paths and actually upload to s3 (woot!)\n",
    "    for i, path_to_file in enumerate(full_stim_paths): \n",
    "        stim_name =  os.path.split(path_to_file)[-1]\n",
    "        if ((check_exists(s3, bucket_name, stim_name)==False) | (overwrite==True)):\n",
    "            print(f'Now uploading {stim_name} | {i+1} of {len(full_stim_paths)}')\n",
    "            s3.Object(bucket_name,stim_name).put(Body=open(path_to_file,'rb')) ## upload stimuli\n",
    "            s3.Object(bucket_name,stim_name).Acl().put(ACL='public-read') ## set access controls\n",
    "        else: \n",
    "            print('Skipping {} | {} of {} because it already exists.'.format(os.path.split(path_to_file)[-1],(i+1),len(full_stim_paths)))\n",
    "        clear_output(wait=True)\n",
    "print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cleared-floor",
   "metadata": {},
   "source": [
    "Example aws output: <br>\n",
    "https://photodraw32.s3.amazonaws.com/0260-ec8c77a0-b084-4598-88aa-7a76d245f1e8_24_photo_saw_n03474779_668_categorydraw.png"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiovascular-snake",
   "metadata": {},
   "outputs": [],
   "source": [
    "for my_bucket_object in b.objects.all():\n",
    "    print(my_bucket_object)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
