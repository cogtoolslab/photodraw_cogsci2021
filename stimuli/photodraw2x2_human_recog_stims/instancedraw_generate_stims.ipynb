{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook generates metadata that associates confederate stimuli to each sketch for the instance-level recognition experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ast\n",
    "import random\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "proj_dir = os.path.abspath('..')\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "feature_dir = os.path.abspath(os.path.join(proj_dir,'features'))\n",
    "stims_dir = os.path.abspath(os.path.join(proj_dir, 'stimuli', 'photodraw32_stims_agglomerate'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data\n",
    "K = pd.read_csv(os.path.join(csv_dir, 'photodraw2x2_sketch_data.csv'))\n",
    "F = np.load(os.path.join(feature_dir, f'FEATURES_FC6_photodraw2x2_sketch.npy'))\n",
    "M = pd.read_csv(os.path.join(feature_dir, f'METADATA_photodraw2x2_sketch.csv'))\n",
    "IMF = np.load(os.path.join(feature_dir, f'FEATURES_FC6_photodraw2x2_image.npy'))\n",
    "IMM = pd.read_csv(os.path.join(feature_dir, f'METADATA_photodraw2x2_image.csv'))\n",
    "IMFI = np.load(os.path.join(feature_dir, f'photodraw2x2_instance_features.npy'))\n",
    "IMMI = pd.read_csv(os.path.join(feature_dir, f'photodraw2x2_metadata_instance.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data into neater formats for us to work with\n",
    "KF = pd.concat([K, pd.DataFrame(F)], axis=1)\n",
    "IMM[['category', 'id', 'instance']] =  IMM.image_id.str.rsplit('_', 2, expand=True)\n",
    "IMM['instance_id'] = IMM['id'] + '_' + IMM['instance'] \n",
    "IMMF = pd.concat([IMM, pd.DataFrame(IMF[IMM.feature_ind])], axis=1)\n",
    "IMMFI = pd.concat([IMMI, pd.DataFrame(IMFI[IMMI.feature_ind])], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First: run image classification on stimuli for sanity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_class_predictions(data, labels):\n",
    "    # setup cross validation framework\n",
    "    kFold = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 0)\n",
    "    logit = LogisticRegression(max_iter=1000)\n",
    "\n",
    "    prob_dict = {}\n",
    "    pred_dict = {} # get it?\n",
    "    for train_ind, test_ind in kFold.split(data, labels):\n",
    "        # fit logistic regression and make indices corresponding to each of the model classes\n",
    "        model = logit.fit(data[train_ind], labels[train_ind])\n",
    "        class_inds = {label : ind for ind, label in enumerate(model.classes_)}\n",
    "\n",
    "        # predict model probabilities and get find true class prediction probability\n",
    "        probarrs = model.predict_proba(data[test_ind])\n",
    "        label_inds = np.asarray([class_inds[label] for label in labels[test_ind]])[:, None]\n",
    "        prob_of_classification = np.take_along_axis(probarrs, label_inds, axis=1).reshape((-1,))\n",
    "\n",
    "        # update dictionaries with probabilities and predictions\n",
    "        prob_dict.update(list(zip(test_ind, prob_of_classification)))\n",
    "        pred_dict.update(list(zip(test_ind, model.predict(data[test_ind]) == labels[test_ind])))\n",
    "\n",
    "    # ensure we are actually getting probabilities\n",
    "    assert all(np.fromiter(prob_dict.values(), dtype = float) <= 1)\n",
    "    assert all(np.fromiter(prob_dict.values(), dtype = float) >= 0)\n",
    "    \n",
    "    return prob_dict, pred_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_dict, pred_dict = compute_class_predictions(IMMF[np.arange(4096)].values, IMMF.category.values)\n",
    "IMMF['prob_true_predict_fc6'] = IMMF.index.map(prob_dict)\n",
    "IMMF['true_predict_fc6'] = IMMF.index.map(pred_dict)\n",
    "\n",
    "# check that we are getting a reasonable classification accuracy\n",
    "IMMF['true_predict_fc6'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanity check that our features are extracted correctly: otherwise we would perform at chance\n",
    "plt.figure(figsize=(6,8))\n",
    "sns.barplot(data = IMMF, x = 'prob_true_predict_fc6', y = 'category');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Least recognizable: ', IMMF.groupby('category')['prob_true_predict_fc6'].mean().nsmallest().index.values)\n",
    "print('Most recognizable: ', IMMF.groupby('category')['prob_true_predict_fc6'].mean().nlargest().index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Goal: get the 8-nearest images corresponding to each sketch\n",
    "\n",
    "#### Store the paths to these images in a dataframe. This will be the metadata for `recogdraw_instance`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reallyRun = False\n",
    "if reallyRun:\n",
    "    # import stimuli data\n",
    "    stims_metadata = pd.read_csv('photodraw32_metadata.csv')\n",
    "    stims_metadata['instance_id'] = stims_metadata.sketchy_filename.str.split('.', expand=True)[0]\n",
    "    sketches_s3_metadata = pd.read_csv('photodraw32_s3_sketches_metadata.csv')\n",
    "\n",
    "    # create dataframe which is supposed to match a sketch to its 8 most similar stimuli\n",
    "    sketch2simstims_metadata = sketches_s3_metadata[sketches_s3_metadata.condition == 'photo']\n",
    "    sketch2simstims_metadata = sketch2simstims_metadata.drop(columns='filepath')\n",
    "    sketch2simstims_metadata = sketch2simstims_metadata.rename(columns = {'filename' : 'sketch_filename',\n",
    "                                                                          's3_url'   : 'sketch_s3_url'})\n",
    "    sketch2simstims_metadata['sketch_file'] = sketch2simstims_metadata.sketch_filename.str.split('.', expand=True)[0]\n",
    "\n",
    "    sketch2simstims_metadata['nearest_photo_filenames'] = ''\n",
    "    sketch2simstims_metadata['nearest_photo_s3_urls']   = ''\n",
    "    sketch2simstims_metadata['true_photo_filename'] = ''\n",
    "    sketch2simstims_metadata['true_photo_s3_url']   = ''\n",
    "\n",
    "    # extract the 8-nearest neighbors for each sketch and store in a dataframe\n",
    "    for index, sketch in KF[KF.condition == 'photo'].iterrows():\n",
    "\n",
    "        sketch_original_image = IMMF[IMMF.image_id == f\"{sketch['category']}_{sketch['imageURL']}\"]\n",
    "        sketch_original_image = sketch_original_image[np.arange(4096)].values[0]\n",
    "\n",
    "        sketch_string = f\"{sketch['gameID']}_\"\\\n",
    "                        f\"{sketch['trialNum']}_\"\\\n",
    "                        f\"{sketch['condition']}_\"\\\n",
    "                        f\"{sketch['category']}_\"\\\n",
    "                        f\"{sketch['imageURL']}_\"\\\n",
    "                        f\"{sketch['goal']}\"\n",
    "        simstims_index = sketch2simstims_metadata[sketch2simstims_metadata.sketch_file == sketch_string].index[0]\n",
    "\n",
    "\n",
    "        all_neighbors = IMMF[IMMF.category == sketch['category']]\n",
    "        knn = NearestNeighbors(n_neighbors=8, metric=\"cosine\") \n",
    "        knn.fit(all_neighbors[np.arange(4096)].values)\n",
    "        _, indices = knn.kneighbors([sketch_original_image]) # find k nearest train neighbours\n",
    "        neighbors = all_neighbors.iloc[indices[0]]\n",
    "\n",
    "        sketch2simstims_metadata.at[simstims_index, 'nearest_photo_filenames'] = list(neighbors.image_id + '.png')\n",
    "        sketch2simstims_metadata.at[simstims_index, 'nearest_photo_s3_urls'] = \\\n",
    "                        list(stims_metadata[stims_metadata['instance_id'].isin(neighbors.instance_id)].s3_url)\n",
    "        sketch2simstims_metadata.at[simstims_index, 'true_photo_filename'] = f'{sketch.category}_{sketch.imageURL}.png'\n",
    "        # a bit messy \n",
    "        for url in sketch2simstims_metadata.at[simstims_index, 'nearest_photo_s3_urls']:\n",
    "            if url.split('/')[-1].split('.')[0].rsplit('_',1)[0] == f'{sketch.imageURL}_{sketch.category}':\n",
    "                sketch2simstims_metadata.at[simstims_index, 'true_photo_s3_url'] = url\n",
    "\n",
    "    # Save out data to csv\n",
    "    sketch2simstims_metadata = sketch2simstims_metadata.drop(columns='sketch_file')\n",
    "    sketch2simstims_metadata.to_csv('photodraw32_instance_validation_metadata.csv', index = False)\n",
    "    sketch2simstims_metadata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(sketch2simstims_metadata[sketch2simstims_metadata['true_photo_s3_url'] == '']) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstration that we can now pull the 8 most similar images of a given sketch in from s3 using our metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch2simstims_metadata = pd.read_csv('photodraw32_instance_validation_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sketch = sketch2simstims_metadata.sample()\n",
    "print(sketch[['category', 'goal']])\n",
    "\n",
    "# sketch\n",
    "response = requests.get(sketch.sketch_s3_url.values[0])\n",
    "img = Image.open(BytesIO(response.content))\n",
    "display(img)\n",
    "\n",
    "# ground truth image\n",
    "img = Image.open(BytesIO(requests.get(sketch.true_photo_s3_url.values[0]).content))\n",
    "display(img)\n",
    "\n",
    "fig = plt.figure(figsize=(8., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(2, 4),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 share_all=True)\n",
    "grid[0].get_yaxis().set_ticks([])\n",
    "grid[0].get_xaxis().set_ticks([])\n",
    "\n",
    "images = [Image.open(BytesIO(requests.get(url).content)) for url in \\\n",
    "          ast.literal_eval(sketch.nearest_photo_s3_urls.values[0])]\n",
    "\n",
    "random.shuffle(images)\n",
    "# images.insert(0, Image.open(os.path.join(stims_dir, f'{a.category.values[0]}_{a.imageURL.values[0]}.png')))\n",
    "for ax, im in zip(grid, images):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12., 8.))\n",
    "grid = ImageGrid(fig, 111,  # similar to subplot(111)\n",
    "                 nrows_ncols=(4, 8),  # creates 2x2 grid of axes\n",
    "                 axes_pad=0.1,  # pad between axes in inch.\n",
    "                 share_all=True)\n",
    "grid[0].get_yaxis().set_ticks([])\n",
    "grid[0].get_xaxis().set_ticks([])\n",
    "\n",
    "images = [Image.open(os.path.join(stims_dir, f'{img_id}.png')) for img_id in all_neighbors.image_id]\n",
    "\n",
    "for ax, im in zip(grid, images):\n",
    "    # Iterating over the grid returns the Axes.\n",
    "    ax.imshow(im)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
