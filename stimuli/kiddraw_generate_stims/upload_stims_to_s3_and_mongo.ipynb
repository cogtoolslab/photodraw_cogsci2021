{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib\n",
    "from matplotlib import pyplot,pylab\n",
    "plt = pyplot\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "sns.set_style('white')\n",
    "import string\n",
    "import pandas as pd\n",
    "import json\n",
    "import pymongo as pm\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### helper funcs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this helps to sort in human order\n",
    "import re\n",
    "\n",
    "def tryint(s):\n",
    "    try:\n",
    "        return int(s)\n",
    "    except ValueError:\n",
    "        return s\n",
    "     \n",
    "def alphanum_key(s):\n",
    "    \"\"\" Turn a string into a list of string and number chunks.\n",
    "        \"z23a\" -> [\"z\", 23, \"a\"]\n",
    "    \"\"\"\n",
    "    return [ tryint(c) for c in re.split('([0-9]+)', s) ]\n",
    "\n",
    "def sort_nicely(l):\n",
    "    \"\"\" Sort the given list in the way that humans expect.\n",
    "    \"\"\"\n",
    "    l.sort(key=alphanum_key)\n",
    "    \n",
    "def load_text(path):\n",
    "    with open(path, 'r') as f:\n",
    "        x = f.readlines()\n",
    "    utt = x[0]\n",
    "    # replace special tokens with question marks\n",
    "    if '<DIA>' in utt:\n",
    "        utt = utt.replace('<DIA>', '-')\n",
    "    if '<UKN>' in utt:\n",
    "        utt = utt.replace('<UKN>', '___')    \n",
    "    return utt\n",
    "\n",
    "def list_files(path, ext='svg'):\n",
    "    result = [y for x in os.walk(path)\n",
    "              for y in glob(os.path.join(x[0], '*.%s' % ext))]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# paths\n",
    "path_to_images = './photodraw2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deborkify image path names\n",
    "cats = [i for i in os.listdir(path_to_images) if i != '.DS_Store']\n",
    "for c, cat in enumerate(cats):\n",
    "    ims = [i for i in os.listdir(os.path.join(path_to_images,cat)) if i != '.DS_Store']\n",
    "    for i, im in enumerate(ims):\n",
    "        os.rename(os.path.join(path_to_images,cat,im),os.path.join(path_to_images,cat,'{}_{}.jpg'.format(cat,i)))\n",
    "#         print os.path.join(path_to_images,cat,'{}_{}.jpg'.format(cat,i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list_files(path_to_images,ext='jpg'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate stimulus dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating dataframe with each cue and their attributes...\n"
     ]
    }
   ],
   "source": [
    "print('Generating dataframe with each cue and their attributes...')    \n",
    "\n",
    "# path to images\n",
    "path_to_images = './photodraw2'\n",
    "# specify list of conditions\n",
    "conditions = ['photo','label']\n",
    "# get list of image paths\n",
    "image_paths = list_files(path_to_images,ext='jpg')\n",
    "# bucket name\n",
    "bucket_name = 'drawbase-demo'\n",
    "# specify dataset name\n",
    "dataset_name = 'photodraw2'\n",
    "\n",
    "condition = [] # photo vs. label\n",
    "category = [] \n",
    "image_id = []\n",
    "image_url = []\n",
    "games = [] # this field keeps track of which games this triplet has been shown in\n",
    "shuffler_ind = []\n",
    "\n",
    "## generate permuted list of triplet indices in order to be able retrieve from triplets pseudorandomly\n",
    "inds = np.arange(len(conditions)*len(image_paths)) \n",
    "shuffled_inds = np.random.RandomState(0).permutation(inds)\n",
    "counter = 0\n",
    "for cond_ind,this_condition in enumerate(conditions):\n",
    "    for im_ind,this_img in enumerate(image_paths):  \n",
    "        condition.append(this_condition)\n",
    "        category.append(this_img.split('/')[-2])\n",
    "        _image_id = this_img.split('/')[-1].split('.')[0]\n",
    "        image_id.append(_image_id)\n",
    "        image_url.append('https://s3.amazonaws.com/{}/{}.jpg'.format(bucket_name,_image_id))\n",
    "        games.append([])\n",
    "        shuffler_ind.append(shuffled_inds[counter])\n",
    "        counter += 1                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating pandas dataframe...\n"
     ]
    }
   ],
   "source": [
    "print('Generating pandas dataframe...') \n",
    "table = [condition,category,image_id,image_url,games,shuffler_ind]\n",
    "headers = ['condition','category','image_id','image_url','games','shuffler_ind']\n",
    "df = pd.DataFrame(table)\n",
    "df = df.transpose()\n",
    "df.columns = headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving out json dictionary out to file...\n"
     ]
    }
   ],
   "source": [
    "## save out to file\n",
    "print('Saving out json dictionary out to file...') \n",
    "stimdict = df.to_dict(orient='records') \n",
    "with open('{}_meta.js'.format(dataset_name), 'w') as fout:\n",
    "    json.dump(stimdict, fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "next todo is to upload this JSON to initialize the new stimulus collection...\n"
     ]
    }
   ],
   "source": [
    "### next todo is to upload this JSON to initialize the new stimulus collection\n",
    "print('next todo is to upload this JSON to initialize the new stimulus collection...')\n",
    "import json\n",
    "J = json.loads(open('{}_meta.js'.format(dataset_name),mode='ru').read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset_name: photodraw2\n",
      "num entries in stim dictionary: 32\n"
     ]
    }
   ],
   "source": [
    "assert len(J)==len(image_paths)*len(conditions)\n",
    "print 'dataset_name: {}'.format(dataset_name)\n",
    "print 'num entries in stim dictionary: {}'.format(len(J))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## remember to establish tunnel to mongodb on remote server first\n",
    "\n",
    "# set vars \n",
    "auth = pd.read_csv('auth.txt', header = None) # this auth.txt file contains the password for the sketchloop user\n",
    "pswd = auth.values[0][0]\n",
    "user = 'sketchloop'\n",
    "host = 'rxdhawkins.me' ## cocolab ip address\n",
    "\n",
    "# have to fix this to be able to analyze from local\n",
    "conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1')\n",
    "db = conn['stimuli']\n",
    "coll = db[dataset_name]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 of 32\n",
      "10 of 32\n",
      "20 of 32\n",
      "30 of 32\n"
     ]
    }
   ],
   "source": [
    "## actually add data now to the database\n",
    "reallyRun = 1\n",
    "if reallyRun:\n",
    "    for (i,j) in enumerate(J):\n",
    "        if i%10==0:\n",
    "            print ('%d of %d' % (i,len(J)))\n",
    "        coll.insert_one(j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "## check how many records have been retrieved\n",
    "a = coll.find({'shuffler_ind':{'$gte':0}})\n",
    "numGames = []\n",
    "for rec in a:\n",
    "    numGames.append(len(rec['games']))\n",
    "b = np.array(numGames)\n",
    "print np.mean(b>0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coll.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
