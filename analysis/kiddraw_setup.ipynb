{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow the instructions of this notebook to generate the csv files used in analysis for kiddraw\n",
    "### If you ran download_data.py, running this code is not necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages and set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pymongo as pm\n",
    "import pandas as pd\n",
    "import socket\n",
    "import json\n",
    "import numpy as np\n",
    "import utils\n",
    "import base64\n",
    "import importlib\n",
    "import time\n",
    "from collections import Counter\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "import matplotlib\n",
    "from matplotlib import pylab, mlab, pyplot\n",
    "%matplotlib inline\n",
    "from IPython.core.pylabtools import figsize, getfigs\n",
    "plt = pyplot\n",
    "import seaborn as sns\n",
    "sns.set_context('talk')\n",
    "sns.set_style('white')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir     = os.path.abspath('..')\n",
    "analysis_dir = os.getcwd()\n",
    "results_dir  = os.path.join(proj_dir, 'results')\n",
    "plot_dir     = os.path.join(results_dir, 'plots')\n",
    "csv_dir      = os.path.join(results_dir, 'csv')\n",
    "exp_dir      = os.path.abspath(os.path.join(proj_dir, 'experiments'))\n",
    "sketch_dir   = os.path.abspath(os.path.join(proj_dir, 'sketches'))\n",
    "gallery_dir  = os.path.abspath(os.path.join(proj_dir, 'gallery'))\n",
    "\n",
    "if socket.gethostname() == 'nightingale':\n",
    "    feature_dir = os.path.abspath('/mnt/pentagon/photodraw/features/')\n",
    "else:\n",
    "    feature_dir = os.path.abspath(os.path.join(proj_dir, 'features'))\n",
    "\n",
    "meta_path      = os.path.abspath(os.path.join(feature_dir, 'metadata_pixels.csv'))\n",
    "image_path     = os.path.abspath(os.path.join(feature_dir, 'flattened_sketches_pixels.npy'))\n",
    "meta_path_fc6  = os.path.abspath(os.path.join(feature_dir, 'METADATA_sketch.csv'))\n",
    "image_path_fc6 = os.path.abspath(os.path.join(feature_dir, 'FEATURES_FC6_sketch_no-channel-norm.npy'))\n",
    "\n",
    "# add helpers to python path\n",
    "if os.path.join(proj_dir, 'utils') not in sys.path:\n",
    "    sys.path.append(os.path.join(proj_dir, 'utils'))\n",
    "\n",
    "def make_dir_if_not_exists(dir_name):\n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    return dir_name\n",
    "\n",
    "## create directories that don't already exist        \n",
    "result = [make_dir_if_not_exists(x) for x in [results_dir, plot_dir, csv_dir, sketch_dir, gallery_dir, feature_dir]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### establish connection to mongo\n",
    "\n",
    "`ssh -fNL 27020:127.0.0.1:27017 jyang@cogtoolslab.org`  \n",
    "`ssh -fNL 27017:127.0.0.1:27017 jyang@cogtoolslab.org`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting to true produces S, T, and K directly from mongo\n",
    "yes = True\n",
    "if yes:\n",
    "    # set vars (auth.txt file contains the password for the sketchloop user)\n",
    "    pswd = auth.values[0][0]\n",
    "    auth = pd.read_csv(os.path.join(analysis_dir, 'auth.txt'), header=None)\n",
    "    decoderpswd = int(pswd[-1])\n",
    "    user = 'sketchloop'\n",
    "    host = 'cogtoolslab.org'\n",
    "\n",
    "    # have to fix this to be able to analyze from local\n",
    "    import socket\n",
    "    if socket.gethostname().split('_')[0] == 'Justin':\n",
    "        conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1:27020')\n",
    "    else:\n",
    "        conn = pm.MongoClient('mongodb://sketchloop:' + pswd + '@127.0.0.1:27017')\n",
    "    db = conn['photodraw']\n",
    "    coll = db['kiddraw']\n",
    "\n",
    "    # set iteration name\n",
    "    iterationName = 'run0'\n",
    "\n",
    "    # how many records do we have in mongo?\n",
    "    print(f\"We have {coll.estimated_document_count()} records in mongo.\")\n",
    "    print(f\"{len(list(coll.find({'iterationName':iterationName, 'eventType':'sketch'})))} of these are sketches.\")\n",
    "    print(f\"{len(list(coll.find({'iterationName':iterationName, 'eventType':'stroke'})))} of these are strokes.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize, transform dataframes\n",
    "#### Call data from mongo server and create dataframes with the relevant metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if yes:\n",
    "    # Sketches\n",
    "    k = coll.find({'iterationName':iterationName, 'eventType':'sketch'})\n",
    "    K = pd.DataFrame(k)\n",
    "\n",
    "    # Strokes\n",
    "    t = coll.find({'iterationName':iterationName, 'eventType':'stroke'})\n",
    "    T = pd.DataFrame(t)\n",
    "\n",
    "    # Surveys\n",
    "    s = coll.find({'iterationName':iterationName, 'eventType':'survey'})\n",
    "    S = pd.DataFrame(s).sort_values('aID').reset_index(drop=True)\n",
    "\n",
    "    responses = []\n",
    "    coolbeans = ''\n",
    "    j = 0\n",
    "    for i in range(len(S.responses)):\n",
    "        if (i % 2 == 0):\n",
    "            coolbeans = S.responses[i][:-1] + ', '\n",
    "            S = S.replace(S['question_order'][i+1], S['question_order'][i])\n",
    "        else:\n",
    "            coolbeans = coolbeans + S.responses[i][1:]\n",
    "            responses.append(json.loads(coolbeans))        \n",
    "            S = S.drop(S.index[j])\n",
    "            j+=1\n",
    "    S = S.reset_index(drop=True)\n",
    "    responses = pd.DataFrame(responses)\n",
    "    S = pd.concat([S, responses], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for encoding and decoding workerIds\n",
    "def scrambler(messages):\n",
    "    encoded = []\n",
    "    for message in messages:\n",
    "        msg = 'mum' + message + 'sus'\n",
    "        msg = ''.join(chr(ord(letter)+2) for letter in msg)\n",
    "        encoded.append(msg)\n",
    "    return encoded\n",
    "\n",
    "def descrambler(messages):\n",
    "    decoded = []\n",
    "    for message in messages:\n",
    "        msg = ''.join(chr(ord(letter)-2) for letter in message)\n",
    "        msg = msg[3::]\n",
    "        msg = msg[:-3]\n",
    "        decoded.append(msg)\n",
    "    return decoded\n",
    "\n",
    "def encoder(messages):\n",
    "    message = messages\n",
    "    for i in range(4):\n",
    "        message = scrambler(message)\n",
    "    return message\n",
    "  \n",
    "def decoder(messages, password):\n",
    "    message = messages\n",
    "    for i in range(password):\n",
    "        message = descrambler(message)\n",
    "    return message\n",
    "\n",
    "if yes:\n",
    "    # encode workerIDs\n",
    "    T['workerId'] = encoder(T['workerId'])\n",
    "    S['workerId'] = encoder(S['workerId'])\n",
    "\n",
    "# use decoder function to decode workerIDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if yes:\n",
    "    # get list of valid game IDs (i.e, subject number)\n",
    "    game_dict = Counter(K['gameID'])\n",
    "\n",
    "    # get gameids that contributed exactly 12 sketches\n",
    "    complete_gameids = [k for (k, v) in game_dict.items() if v == 12]\n",
    "\n",
    "    # subset stroke/sketch dataframes by being complete AND also exclude practice\n",
    "    subset = True\n",
    "    if (subset and T['gameID'].nunique() != len(complete_gameids)):\n",
    "        T = T[(T['gameID'].isin(complete_gameids))].reset_index(drop=True)\n",
    "        K = K[(K['gameID'].isin(complete_gameids))].reset_index(drop=True)\n",
    "\n",
    "    print('We have {} unique stroke records in all {} of our complete games.'.format(T.shape[0], len(complete_gameids)))\n",
    "    print('We have {} unique sketch records in all {} of our complete games.'.format(K.shape[0], len(complete_gameids)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if yes:\n",
    "    # add gameIDs to survey data\n",
    "    keys_gameID = list(T.sort_values('aID')['gameID'].unique())\n",
    "    values_aID = list(T.sort_values('aID')['aID'].unique())\n",
    "    values_aID = values_aID[:36] + ['3MX2NQ3YCDUJZ0KA8WJ4KDVBNTOX5Q'] + values_aID[36:]\n",
    "    dictionary = dict(zip(keys_gameID, values_aID))\n",
    "\n",
    "    S['gameID'] = list(dictionary.keys())\n",
    "    K['aID'] = K['gameID'].map(dictionary)\n",
    "\n",
    "    # add photoids to sketch data\n",
    "    photoids = []\n",
    "    for index, row in K.iterrows():\n",
    "        if row['condition'] == 'photo':\n",
    "            photoids.append(int(row['imageURL'][-5]))\n",
    "        else:\n",
    "            photoids.append('text')\n",
    "    K = K.assign(photoid=np.asarray(photoids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if yes:\n",
    "    # adds activeSketchTime to K, and sorts the K, T values lexicographically by gameID and then trialNum\n",
    "    K = K.sort_values(by=['gameID', 'trialNum']).reset_index(drop=True)\n",
    "    T = T.sort_values(by=['gameID', 'trialNum']).reset_index(drop=True)\n",
    "    nmnm = []\n",
    "    for gID in K.gameID.unique():\n",
    "        temp = T[T['gameID'] == gID]\n",
    "        for i in temp.trialNum.unique():\n",
    "            temp2 = temp[temp['trialNum'] == i]\n",
    "            nmnm.append(temp2['endStrokeTime'].iloc[-1]-temp2['startStrokeTime'].iloc[0])\n",
    "    K = K.assign(activeSketchTime=nmnm)\n",
    "\n",
    "    # assigns totalInk to K\n",
    "    totalInk = pd.DataFrame(T.groupby(['gameID', 'trialNum'])['arcLength'].aggregate(np.sum)).reset_index()['arcLength']\n",
    "    K = K.assign(totalInk=totalInk)\n",
    "\n",
    "    # adds flags to K stating whether or not to exclude the sketch from data analysis\n",
    "    K = utils.preprocess_sketches(K)\n",
    "\n",
    "    # add labels for category-photoid and category-condition pairs\n",
    "    K = K.assign(cat_id=K.category + '_' + K.photoid)\n",
    "    K = K.assign(cat_cond=K.category + '_' + K.condition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert rgba data to rgb is in rgba, and get everything in the right dimensions\n",
    "def rgba2rgb(rgba, background=(255, 255, 255)):\n",
    "    row, col, ch = rgba.shape\n",
    "\n",
    "    if ch == 3:\n",
    "        return rgba\n",
    "\n",
    "    assert ch == 4, 'RGBA image has 4 channels.'\n",
    "\n",
    "    rgb = np.zeros((row, col, 3), dtype='float32')\n",
    "    r, g, b, a = rgba[:, :, 0], rgba[:, :, 1], rgba[:, :, 2], rgba[:, :, 3]\n",
    "\n",
    "    a = np.asarray(a, dtype='float32') / 255.0\n",
    "\n",
    "    R, G, B = background\n",
    "\n",
    "    rgb[:, :, 0] = r * a + (1.0 - a) * R\n",
    "    rgb[:, :, 1] = g * a + (1.0 - a) * G\n",
    "    rgb[:, :, 2] = b * a + (1.0 - a) * B\n",
    "\n",
    "    return np.asarray(rgb, dtype='double')\n",
    "\n",
    "\n",
    "if yes:\n",
    "    # make an image array of (732x244x244x3) from raw png data\n",
    "    lis = []\n",
    "    ist = []\n",
    "    for i in range(len(K['pngData'])):\n",
    "        lis.append(np.array(Image.open(BytesIO(base64.b64decode(K['pngData'][i]))).resize((224, 224))))\n",
    "        ist.append(np.array(rgba2rgb(lis[i])))\n",
    "    lis = np.array(lis)\n",
    "    ist = np.array(ist)\n",
    "\n",
    "    # make a 732 x (224*224*3) feature vector of pixels\n",
    "    F = np.array([ist[i].flatten() for i in range(len(ist))])\n",
    "\n",
    "    # load in fc6 feature vectors\n",
    "    F_fc6 = np.load(image_path_fc6)\n",
    "\n",
    "    # normalize both feature vectors mean-wise\n",
    "    F_norm = F - F.mean(axis=0)\n",
    "    F_fc6_norm = F_fc6 - F_fc6.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if yes:\n",
    "    classes_map = {'airplane':0, \n",
    "                   'bike':1, \n",
    "                   'bird':2, \n",
    "                   'car':3, \n",
    "                   'cat':4, \n",
    "                   'chair':5, \n",
    "                   'cup':6, \n",
    "                   'hat':7, \n",
    "                   'house':8, \n",
    "                   'rabbit':9, \n",
    "                   'tree':10, \n",
    "                   'watch':11}\n",
    "    kFold = KFold(n_splits = 5)\n",
    "    time0 = time.time()\n",
    "    logit = LogisticRegression(max_iter=1000)\n",
    "    sketch_probs_lists = []\n",
    "    i = 1\n",
    "    for train_index, test_index in kFold.split(F_fc6_norm):\n",
    "        model = logit.fit(F_fc6_norm[train_index], K['category'][train_index])\n",
    "        probarrs = model.predict_proba(F_fc6_norm[test_index])\n",
    "        actual = K['category'][test_index].values\n",
    "        probs = [prob[classes_map[act]] for prob, act in zip(probarrs, actual)]\n",
    "        probarr = np.array(list(zip(test_index, actual, probs)))\n",
    "        sketch_probs_lists.append(probarr)\n",
    "        print(f'On loop number {i}. {time.time() - time0} seconds since starting. \\r', end=\"\")\n",
    "        i += 1\n",
    "    sketch_probs_arrays = np.vstack(sketch_probs_lists)\n",
    "    pred_probs = pd.DataFrame(sketch_probs_arrays, columns = ['sketch_index', 'cat_codes_true', 'prob_truth_fc6'])\n",
    "\n",
    "    K = K.assign(prob_true_predict_fc6 = pred_probs.prob_truth_fc6.astype(float))\n",
    "\n",
    "    # pixel-level features\n",
    "    time1 = time.time()\n",
    "    logit = LogisticRegression(max_iter=1000)\n",
    "    sketch_probs_lists = []\n",
    "    i = 1\n",
    "    for train_index, test_index in kFold.split(F_norm):\n",
    "        model = logit.fit(F_norm[train_index], K['category'][train_index])\n",
    "        probarrs = model.predict_proba(F_norm[test_index])\n",
    "        actual = K['category'][test_index].values\n",
    "        probs = [prob[classes_map[act]] for prob, act in zip(probarrs, actual)]\n",
    "        probarr = np.array(list(zip(test_index, actual, probs)))\n",
    "        sketch_probs_lists.append(probarr)\n",
    "        print(f'On loop number {i}. {time.time() - time0} seconds since starting the script. {time.time() - time1} seconds since starting the pixel-level CV. \\r', end=\"\")\n",
    "        i += 1\n",
    "    sketch_probs_arrays2 = np.vstack(sketch_probs_lists)\n",
    "    pred_probs2 = pd.DataFrame(sketch_probs_arrays2, columns = ['sketch_index', 'cat_codes_true', 'prob_truth'])\n",
    "    K = K.assign(prob_true_predict_pixel = pred_probs2.prob_truth.astype(float))\n",
    "    K['prob_true_predict_logodds'] = K.prob_true_predict_pixel.transform(lambda p: np.log10(p/(1-p))).values\n",
    "    K['prob_true_predict_fc6_logodds'] = K.prob_true_predict_fc6.transform(lambda p: np.log10(p/(1-p))).values\n",
    "\n",
    "    # does every sketch have a valid probability?\n",
    "    assert all(K.prob_true_predict_fc6 >= 0) & all(K.prob_true_predict_fc6 <= 1)\n",
    "    assert all(K.prob_true_predict_pixel >= 0) & all(K.prob_true_predict_pixel <= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if yes:\n",
    "    # save data out to csv\n",
    "    T.to_csv(os.path.join(csv_dir, 'photodraw_stroke_data.csv'), index=False)\n",
    "    K.to_csv(os.path.join(csv_dir, 'photodraw_sketch_data.csv'), index=False)\n",
    "    S.to_csv(os.path.join(csv_dir, 'photodraw_survey_data.csv'), index=False)\n",
    "    np.save(image_path, F)\n",
    "else:\n",
    "    # read in csv\n",
    "    T = pd.read_csv(os.path.join(csv_dir, 'photodraw_stroke_data.csv'))\n",
    "    K = pd.read_csv(os.path.join(csv_dir, 'photodraw_sketch_data.csv'))\n",
    "    S = pd.read_csv(os.path.join(csv_dir, 'photodraw_survey_data.csv'))\n",
    "    F = np.load(image_path)\n",
    "    F_fc6 = np.load(image_path_fc6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### render out sketches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importlib.reload(utils)\n",
    "utils.render_images(K,\n",
    "                    data='pngData',\n",
    "                    metadata=['gameID', 'trialNum', 'condition', 'category', 'photoid'],\n",
    "                    out_dir=sketch_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sketch gallery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sketch_paths = sorted([sketch_path for sketch_path in os.listdir(sketch_dir)])\n",
    "gameids = list(np.unique([i.split('_')[0] for i in sketch_paths]))\n",
    "\n",
    "if (len(os.listdir(gallery_dir)) == 0):\n",
    "    # generate gallery for each participant\n",
    "    for gind, game in enumerate(gameids):\n",
    "        print('Generating sketch gallery for participant: {} | {} of {}'.format(game, gind+1, len(gameids)))\n",
    "        # get list of all sketch paths JUST from current game\n",
    "        game_sketch_paths = [path for path in sketch_paths if path.split('_')[0] == game]\n",
    "        fig = plt.figure(figsize=(8, 12))\n",
    "        for i, f in enumerate(game_sketch_paths):\n",
    "            # open image\n",
    "            im = Image.open(os.path.join(sketch_dir, f))\n",
    "            # get metadata\n",
    "            gameid = f.split('_')[0]\n",
    "            trialNum = f.split('_')[1]\n",
    "            condition = f.split('_')[2]\n",
    "            category = f.split('_')[3].split('.')[0]\n",
    "            # make gallery\n",
    "            p = plt.subplot(3, 4, i+1)\n",
    "            plt.imshow(im)\n",
    "            sns.set_style('white')\n",
    "            k = p.get_xaxis().set_ticklabels([])\n",
    "            k = p.get_yaxis().set_ticklabels([])\n",
    "            k = p.get_xaxis().set_ticks([])\n",
    "            k = p.get_yaxis().set_ticks([])\n",
    "            p.axis('off')\n",
    "            plt.title('{} {} {}'.format(trialNum, condition, category))\n",
    "        plt.suptitle(gameid)\n",
    "        fname = '{}.png'.format(gameid)\n",
    "        plt.savefig(os.path.join(gallery_dir, fname))\n",
    "        plt.close(fig)\n",
    "    print('Done!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make flattened pixel data and metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make an image array of (732x244x244x3) from raw png data\n",
    "lis = []\n",
    "ist = []\n",
    "for i in range(len(K['pngData'])):\n",
    "    lis.append(np.array(Image.open(BytesIO(base64.b64decode(K['pngData'][i]))).resize((224, 224))))\n",
    "    ist.append(np.array(rgba2rgb(lis[i])))\n",
    "lis = np.array(lis)\n",
    "ist = np.array(ist)\n",
    "\n",
    "# make a 732 x (224*224*3) feature vector of pixels\n",
    "F = np.array([ist[i].flatten() for i in range(len(ist))])\n",
    "\n",
    "# make metadata containing _id, gameID, condition, category, numStrokes, trialNum, and photo-id\n",
    "photoid = [i[-5] for i in K['imageURL']]\n",
    "M = np.array(K[['_id', 'gameID', 'trialNum', 'condition', 'category']])\n",
    "M = np.hstack((M, np.array(photoid).astype(int).reshape(732, 1)))\n",
    "M = pd.DataFrame(M, columns=['_id', 'gameID', 'trialNum', 'condition', 'category', 'photoid'])\n",
    "for i in range(len(M)):\n",
    "    if (M['condition'][i] == 'text'):\n",
    "        M['photoid'][i] = 'text'\n",
    "M = M.assign(cat_id=M.category.astype(str) + M.photoid.astype(str))\n",
    "M = M.assign(cat_cond=M.category + M.condition)\n",
    "M = M.assign(cond_codes=M.condition.astype('category').cat.codes)\n",
    "M = M.assign(cat_codes=M.category.astype('category').cat.codes)\n",
    "M = M.assign(photoid_codes=M.photoid.astype('category').cat.codes)\n",
    "M = M.assign(cat_cond_codes=M.cat_cond.astype('category').cat.codes)\n",
    "M = M.assign(cat_id_codes=M.cat_id.astype('category').cat.codes)\n",
    "\n",
    "M = M.join(K[['isOutlier', 'isInvalid']])\n",
    "\n",
    "# save out the low-level data\n",
    "np.save(image_path, F), M.to_csv(meta_path, index=False)\n",
    "\n",
    "# save out unflattened sketch data if you want to run extended_sketches\n",
    "unflattened_ones = os.path.abspath(os.path.join(feature_dir, 'unflattened_sketches_pixel.npy'))\n",
    "np.save(unflattened_ones, ist)\n",
    "\n",
    "M.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to true if the metadata is still in the old format\n",
    "M_fc6 = pd.read_csv(meta_path_fc6)\n",
    "F_fc6 = np.load(image_path_fc6)\n",
    "\n",
    "if 'cat_cond_codes' not in M_fc6.columns.values:\n",
    "    temp = []\n",
    "    for index, row in M_fc6.iterrows():\n",
    "        temp.append(np.array(row['sketch_id'].split('\\\\')[1].split('_')))\n",
    "    M_fc6 = pd.DataFrame(np.vstack(tuple(temp)), columns=['gameID', 'trialNum', 'condition', 'category', 'photoid'])\n",
    "    M_fc6['trialNum'] = M_fc6.trialNum.astype(int)\n",
    "    M_fc6 = M_fc6.assign(cat_id=M_fc6.category + M_fc6.photoid)\n",
    "    M_fc6 = M_fc6.assign(cat_id_codes=M_fc6.cat_id.astype('category').cat.codes)\n",
    "    M_fc6 = M_fc6.assign(cat_codes=M_fc6.category.astype('category').cat.codes)\n",
    "    M_fc6 = M_fc6.assign(cat_cond_codes=(M_fc6.category + M_fc6.condition).astype('category').cat.codes)\n",
    "\n",
    "    F_fc6 = F_fc6[M_fc6.sort_values(['gameID', 'trialNum']).index]\n",
    "    M_fc6 = M_fc6.sort_values(['gameID', 'trialNum']).reset_index(drop=True)\n",
    "\n",
    "    M_fc6 = M_fc6.join(K[['isOutlier', 'isInvalid']])\n",
    "\n",
    "    M_fc6.to_csv(meta_path_fc6, index=False)\n",
    "    np.save(image_path_fc6, F_fc6)\n",
    "else:\n",
    "    print('Up to date!')\n",
    "    pass\n",
    "M_fc6.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### go to command line and nagivate to analysis directory, run the following for fc6 features\n",
    "\n",
    "`python extract_features.py --data=/photodraw/sketches/ --layer_ind=5 --data_type=sketch --spatial_avg=True --channel_norm=False --out_dir=/photodraw/features/` \n",
    "\n",
    "Turns out you don't need to do this since the features are already extracted and saved directly on github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run = True\n",
    "if run:\n",
    "    M_fc6 = pd.read_csv(os.path.join(feature_dir, \"photodraw12/METADATA_photodraw_sketch.csv\"))\n",
    "    F_fc6 = np.load(os.path.join(feature_dir, \"photodraw12/FEATURES_FC6_photodraw_sketch.npy\"))\n",
    "    K = pd.read_csv(os.path.join(csv_dir, 'photodraw_sketch_data.csv'))\n",
    "\n",
    "    if 'cat_cond_codes' not in M_fc6.columns.values:\n",
    "        temp = []\n",
    "        for index, row in M_fc6.iterrows():\n",
    "            temp.append(np.array(row['image_id'].split('\\\\')[1].split('_')))\n",
    "        M_fc6 = pd.DataFrame(np.vstack(tuple(temp)), columns=['gameID', 'trialNum', 'condition', 'category', 'photoid'])\n",
    "        M_fc6['trialNum'] = M_fc6.trialNum.astype(int)\n",
    "        M_fc6 = M_fc6.assign(cat_id=M_fc6.category + M_fc6.photoid)\n",
    "        M_fc6 = M_fc6.assign(cat_id_codes=M_fc6.cat_id.astype('category').cat.codes)\n",
    "        M_fc6 = M_fc6.assign(cat_codes=M_fc6.category.astype('category').cat.codes)\n",
    "        M_fc6 = M_fc6.assign(cat_cond_codes=(M_fc6.category + M_fc6.condition).astype('category').cat.codes)\n",
    "\n",
    "        F_fc6 = F_fc6[M_fc6.sort_values(['gameID', 'trialNum']).index]\n",
    "        M_fc6 = M_fc6.sort_values(['gameID', 'trialNum']).reset_index(drop=True)\n",
    "\n",
    "        M_fc6 = M_fc6.join(K[['isOutlier', 'isInvalid']])\n",
    "\n",
    "        M_fc6.to_csv(os.path.join(feature_dir, \"photodraw12/METADATA_photodraw_sketch.csv\"), index=False)\n",
    "        np.save(os.path.join(feature_dir, \"photodraw12/FEATURES_FC6_photodraw_sketch.npy\"), F_fc6)\n",
    "\n",
    "    F = np.load(image_path)\n",
    "    F_norm = F - F.mean(axis=0)\n",
    "    F_fc6_norm = F_fc6 - F_fc6.mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extra code that might become relevant again\n",
    "classes_map = {'airplane':0, \n",
    "               'bike':1, \n",
    "               'bird':2, \n",
    "               'car':3, \n",
    "               'cat':4, \n",
    "               'chair':5, \n",
    "               'cup':6, \n",
    "               'hat':7, \n",
    "               'house':8, \n",
    "               'rabbit':9, \n",
    "               'tree':10, \n",
    "               'watch':11}\n",
    "kFold = KFold(n_splits = 5)\n",
    "time0 = time.time()\n",
    "logit = LogisticRegression(max_iter=1000)\n",
    "sketch_probs_lists = []\n",
    "sketch_preds_lists = []\n",
    "i = 1\n",
    "for train_index, test_index in kFold.split(F_fc6_norm):\n",
    "    model = logit.fit(F_fc6_norm[train_index], K['category'][train_index])\n",
    "    probarrs = model.predict_proba(F_fc6_norm[test_index])\n",
    "    preds = model.predict(F_fc6_norm[test_index])\n",
    "    actual = K['category'][test_index].values\n",
    "    probs = [prob[classes_map[act]] for prob, act in zip(probarrs, actual)]\n",
    "    probarr = np.array(list(zip(test_index, actual, probs)))\n",
    "    predarr = np.array(list(zip(test_index, actual, preds)))\n",
    "    sketch_probs_lists.append(probarr)\n",
    "    sketch_preds_lists.append(predarr)\n",
    "    print(f'On loop number {i}. {time.time() - time0} seconds since starting. \\r', end=\"\")\n",
    "    i += 1\n",
    "sketch_probs_arrays = np.vstack(sketch_probs_lists)\n",
    "sketch_preds_arrays = np.vstack(sketch_preds_lists)\n",
    "pred_probs = pd.DataFrame(sketch_probs_arrays, columns = ['sketch_index', 'cat_codes_true', 'prob_truth_fc6'])\n",
    "preds = pd.DataFrame(sketch_preds_arrays, columns = ['sketch_index', 'cat_codes_true', 'truth_fc6'])\n",
    "\n",
    "K = K.assign(prob_true_predict_fc6 = pred_probs.prob_truth_fc6.astype(float))\n",
    "K = K.assign(true_predict_fc6 = preds.truth_fc6 == preds.cat_codes_true)\n",
    "\n",
    "# pixel-level features\n",
    "time1 = time.time()\n",
    "logit = LogisticRegression(max_iter=1000)\n",
    "sketch_probs_lists = []\n",
    "sketch_preds_lists = []\n",
    "i = 1\n",
    "for train_index, test_index in kFold.split(F_norm):\n",
    "    model = logit.fit(F_norm[train_index], K['category'][train_index])\n",
    "    probarrs = model.predict_proba(F_norm[test_index])\n",
    "    actual = K['category'][test_index].values\n",
    "    probs = [prob[classes_map[act]] for prob, act in zip(probarrs, actual)]\n",
    "    preds = model.predict(F_norm[test_index])\n",
    "    probarr = np.array(list(zip(test_index, actual, probs)))\n",
    "    predarr = np.array(list(zip(test_index, actual, preds)))\n",
    "    sketch_probs_lists.append(probarr)\n",
    "    sketch_preds_lists.append(predarr)\n",
    "    print(f'On loop number {i}. {time.time() - time0} seconds since starting the script. {time.time() - time1} seconds since starting the pixel-level CV. \\r', end=\"\")\n",
    "    i += 1\n",
    "sketch_probs_arrays2 = np.vstack(sketch_probs_lists)\n",
    "sketch_preds_arrays2 = np.vstack(sketch_preds_lists)\n",
    "pred_probs2 = pd.DataFrame(sketch_probs_arrays2, columns = ['sketch_index', 'cat_codes_true', 'prob_truth'])\n",
    "preds2 = pd.DataFrame(sketch_preds_arrays2, columns = ['sketch_index', 'cat_codes_true', 'truth_pixels'])\n",
    "K = K.assign(prob_true_predict_pixel = pred_probs2.prob_truth.astype(float))\n",
    "K = K.assign(true_predict_pixel = preds2.truth_pixels == preds2.cat_codes_true)\n",
    "K['prob_true_predict_logodds'] = K.prob_true_predict_pixel.transform(lambda p: np.log10(p/(1-p))).values\n",
    "K['prob_true_predict_fc6_logodds'] = K.prob_true_predict_fc6.transform(lambda p: np.log10(p/(1-p))).values\n",
    "\n",
    "# does every sketch have a valid probability?\n",
    "assert all(K.prob_true_predict_fc6 >= 0) & all(K.prob_true_predict_fc6 <= 1)\n",
    "assert all(K.prob_true_predict_pixel >= 0) & all(K.prob_true_predict_pixel <= 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
