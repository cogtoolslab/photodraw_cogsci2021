{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory analyses for photodraw2x2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import data and set up paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import math\n",
    "import utils\n",
    "import socket\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import combinations \n",
    "\n",
    "from scipy import stats\n",
    "from scipy.stats import f\n",
    "from scipy.stats import ttest_rel\n",
    "from scipy.stats import ttest_ind\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.spatial.distance import pdist, squareform\n",
    "\n",
    "from utils import generate_acc_probs, generate_acc_probs_2x2, generate_2x2_plots, \\\n",
    "perform_cross_validation, perform_cross_validation_twice, adjacent_plots, cat_cond_diffplots\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# directory & file hierarchy\n",
    "proj_dir = os.path.abspath('..')\n",
    "results_dir = os.path.join(proj_dir,'results')\n",
    "plot_dir = os.path.join(results_dir,'plots')\n",
    "csv_dir = os.path.join(results_dir,'csv')\n",
    "if socket.gethostname() == 'nightingale':\n",
    "    feature_dir = os.path.abspath('/mnt/pentagon/photodraw/features/')\n",
    "else:\n",
    "    feature_dir = os.path.abspath(os.path.join(proj_dir,'features'))\n",
    "\n",
    "def make_dir_if_not_exists(dir_name):   \n",
    "    if not os.path.exists(dir_name):\n",
    "        os.makedirs(dir_name)\n",
    "    return dir_name\n",
    "\n",
    "## create directories that don't already exist        \n",
    "result = [make_dir_if_not_exists(x) for x in [results_dir,plot_dir,csv_dir,feature_dir]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# modify data to get typicality rating information\n",
    "\n",
    "K = pd.read_csv(os.path.join(csv_dir, 'photodraw2x2_sketch_data.csv'))\n",
    "T = pd.read_csv(os.path.join(csv_dir, 'photodraw2x2_stroke_data.csv'))\n",
    "S = pd.read_csv(os.path.join(csv_dir, 'photodraw2x2_survey_data.csv'))\n",
    "R = pd.read_csv(os.path.join(csv_dir, 'photodraw_sketchy32_typicality_ratings.csv'))\n",
    "\n",
    "R = R[(R.repeat_offender == False) &\n",
    "      (R.tooDissimilar == False)   &\n",
    "      (R.failed_catches == False)  &\n",
    "      (R.catch_trial == False)]\n",
    "R['imageURL'] = R.img_id.str.split('/', expand=True).iloc[:,-1].str.split('_', expand=True)\\\n",
    "                                                               .iloc[:,:2].agg('_'.join, axis=1)\n",
    "\n",
    "rara = pd.DataFrame(R.groupby(['imageURL', 'category']).enumerated_ratings.mean()).reset_index()  \n",
    "rara['isTypical'] = rara.apply(lambda row: row.enumerated_ratings >= \\\n",
    "                               rara[rara.category == row.category].enumerated_ratings.median(), axis = 1)\n",
    "rara['enumerated_ratings'] = rara['enumerated_ratings'] + 0.001 * (np.random.rand(len(rara)) - 0.5)\n",
    "rara['decile'] =  rara.groupby(['category'])['enumerated_ratings'].transform(\n",
    "                     lambda x: pd.qcut(x, 8, labels=range(8)))\n",
    "\n",
    "\n",
    "K['decile'] = K.imageURL.map(dict(zip(rara.imageURL, rara.decile)))\n",
    "K['isTypical'] = K.imageURL.map(dict(zip(rara.imageURL, rara.isTypical)))\n",
    "\n",
    "cat_ratings_map = R.groupby('category').enumerated_ratings.mean().to_dict()\n",
    "inst_ratings_map = R.groupby('imageURL').enumerated_ratings.mean().to_dict()\n",
    "K['cat_typicality'] = K.category.map(cat_ratings_map)\n",
    "K['inst_typicality'] = K.imageURL.map(inst_ratings_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic barplots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Is there more effort being spent in one goal over another? Is there more effort being spent in one condition over another?\n",
    "\n",
    "It appears so: participants put more effort drawing object instances over drawing object categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# paired barplots with condiiton\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=K[K['isOutlier'] == False], kind=\"bar\",\n",
    "    x=\"condition\", y=\"activeSketchTime\", hue=\"goal\", palette=\"dark\", alpha=.7, height=5\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"active sketch time (ms)\")\n",
    "plt.title('Active sketching time per sketch');\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=K[K['isOutlier'] == False], kind=\"bar\",\n",
    "    x=\"condition\", y=\"totalInk\", hue=\"goal\", palette=\"dark\", alpha=.7, height=5\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"Total ink used\")\n",
    "plt.title('Total ink used per sketch');\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=K[K['isOutlier'] == False], kind=\"bar\",\n",
    "    x=\"condition\", y=\"numStrokes\", hue=\"goal\", palette=\"dark\", alpha=.7, height=5\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"Number of strokes\")\n",
    "plt.title('Number of strokes per sketch');\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=K[K['isOutlier'] == False], kind=\"bar\",\n",
    "    x=\"condition\", y=\"prob_true_predict_fc6\", hue=\"goal\", palette=\"dark\", alpha=.7, height=5\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"probability\")\n",
    "plt.title('Probability of correct classification');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can also view goal on the x-axis instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=K[K['isOutlier'] == False], kind=\"bar\",\n",
    "    x=\"goal\", y=\"activeSketchTime\", hue=\"condition\", palette=\"dark\", alpha=.7, height=5\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"active sketch time (ms)\")\n",
    "plt.title('Active sketching time per sketch');\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=K[K['isOutlier'] == False], kind=\"bar\",\n",
    "    x=\"goal\", y=\"totalInk\", hue=\"condition\", palette=\"dark\", alpha=.7, height=5\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"Total ink used\")\n",
    "plt.title('Total ink used per sketch');\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=K[K['isOutlier'] == False], kind=\"bar\",\n",
    "    x=\"goal\", y=\"numStrokes\", hue=\"condition\", palette=\"dark\", alpha=.7, height=5\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"Number of strokes\")\n",
    "plt.title('Number of strokes per sketch');\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=K[K['isOutlier'] == False], kind=\"bar\",\n",
    "    x=\"goal\", y=\"prob_true_predict_fc6\", hue=\"condition\", palette=\"dark\", alpha=.7, height=5\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"probability\")\n",
    "plt.title('Probability of correct classification');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=K[K['isOutlier'] == False], kind=\"bar\",\n",
    "    x=\"experiment\", y=\"numStrokes\", hue=\"true_predict_fc6\", palette=\"dark\", alpha=.7, height=5, size = 5, aspect = 1.3\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"number of strokes\")\n",
    "g._legend.set_title('Correct classification')\n",
    "plt.title('Do more strokes yield higher classification accuracy?');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=K[K['isOutlier'] == False], kind=\"bar\",\n",
    "    x=\"experiment\", y=\"activeSketchTime\", hue=\"true_predict_fc6\", palette=\"dark\", alpha=.7, height=5, size = 5, aspect = 1.3\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"active sketch time (ms)\")\n",
    "g._legend.set_title('Correct prediction')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "g = sns.catplot(\n",
    "    data=K[K['isOutlier'] == False], kind=\"bar\",\n",
    "    x=\"experiment\", y=\"totalInk\", hue=\"true_predict_fc6\", palette=\"dark\", alpha=.7, height=5, size = 5, aspect = 1.3\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"\", \"total ink\")\n",
    "g._legend.set_title('Correct prediction')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Does the greater detail in instancedraw-text facilitate discrimination at the category level?\n",
    "\n",
    "#### It appears that categorydraw-text is more discriminable at the category level than instancedraw-text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data = K[K['isOutlier'] == False], x = 'experiment', y = 'prob_true_predict')\n",
    "plt.title('Probability of correct classification')\n",
    "plt.ylabel('probability');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data = K[K['isOutlier'] == False], x = 'experiment', y = 'prob_true_predict_fc6')\n",
    "plt.title('Probability of correct classification')\n",
    "plt.ylabel('probability');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in ['numStrokes', 'activeSketchTime', 'totalInk', 'prob_true_predict_fc6']:\n",
    "    photodata = K[K.experiment == 'categorydraw-text'][var].values\n",
    "    textdata = K[K.experiment == 'instancedraw-text'][var].values\n",
    "    \n",
    "    print(f\"Is {var} significantly different between the two experiments?:\")\n",
    "    \n",
    "    # Are the variances approximately equal?\n",
    "    varstats = stats.levene(photodata, textdata)\n",
    "    print(\"Testing for equality of variance:\")\n",
    "    print(f\"Levene test stat: {varstats[0]}. p-value: {varstats[1]}\")\n",
    "    if stats.levene(photodata, textdata)[1] < 0.05:\n",
    "        welchtest = stats.ttest_ind(photodata, textdata, equal_var = False)\n",
    "        print('The assumption for equality of variance is violated! Using Welch\\'s t-test (two-sided), we get:')\n",
    "        print(f'Welch\\'s test stat: {welchtest[0]}. p-value: {welchtest[1]}\\n')\n",
    "    else:\n",
    "        ttest = stats.ttest_ind(photodata, textdata)\n",
    "        print('The assumption for equality of variance holds. Using student\\'s t-test (two-sided), we get:')\n",
    "        print(f'Student\\'s t-test: {ttest[0]}. p-value: {ttest[1]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-statistic analyses: between category variance vs. within photo-id variance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f_stat(features, metadata, between_groups = 'category'):\n",
    "    mean_features = [features[i[1].values].mean(axis=0) for i in metadata.groupby(between_groups).feature_ind]\n",
    "    overall_features = features[metadata.feature_ind.values].mean(axis = 0)\n",
    "    \n",
    "    between_group_var = 0\n",
    "    within_group_var = 0\n",
    "    for cat, group in zip(metadata[between_groups].unique(), mean_features):\n",
    "        nsketches = len(metadata[metadata[between_groups] == cat])\n",
    "        between_group_var += nsketches * (np.linalg.norm(group - overall_features))**2 \n",
    "        \n",
    "        diff = features[metadata[metadata[between_groups] == cat].feature_ind] - mean_features[0]\n",
    "        within_group_var += sum((np.linalg.norm(diff , axis = 1))**2)\n",
    "        \n",
    "    between_group_var /= len(mean_features) - 1\n",
    "    within_group_var  /= len(features[metadata.feature_ind.values]) - len(mean_features)\n",
    "    \n",
    "    return between_group_var / within_group_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(get_f_stat(inst_text_fc6, K_inst_text))\n",
    "print(get_f_stat(cat_text_fc6, K_cat_text))\n",
    "print(get_f_stat(sketchy_fc6, sketchy_meta_fc6))\n",
    "F_stat = get_f_stat(sketchy_fc6, sketchy_meta_fc6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fstats = []\n",
    "for cat in sketchy_meta_fc6.category.unique():\n",
    "    sketchy_meta_cat = sketchy_meta_fc6[sketchy_meta_fc6.category == cat]\n",
    "    fstats.append(get_f_stat(sketchy_fc6, sketchy_meta_cat, between_groups='photo_id'))\n",
    "sum(fstats) / len(fstats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plot pdf of F-distribution with df1 = 31, df2 = 24\n",
    "x = np.linspace(0, 100, 5000)\n",
    "plt.plot(x, f(31, 19490).pdf(x), label=r'F-distribution, df$_1$ = 11, df$_2$= 24')\n",
    "plt.axvline(F_stat, color='green');\n",
    "plt.xlabel('F'), plt.ylabel('Density'), \n",
    "plt.suptitle('Between-class (category) variability vs within-class (photo-id) variability');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct RDMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_category_features_photo = pd.DataFrame([sketchy_fc6[i[1].values].mean(axis=0) \\\n",
    "                                       for i in sketchy_meta_fc6.groupby('category').feature_ind])\n",
    "mean_category_features_photo['category'] = sketchy_meta_fc6.category.unique()\n",
    "mean_category_features_photo['condition'] = 'photo'\n",
    "\n",
    "mean_category_features_text = []\n",
    "mean_category_features_text_cat = []\n",
    "mean_category_features_text_inst = []\n",
    "K2 = K.sort_values('category', ignore_index=True)\n",
    "for group in K2.groupby('category'):\n",
    "    tempdf = pd.DataFrame(group[1])\n",
    "    mean_category_features_text.append(\\\n",
    "        np.concatenate((cats_fc6[tempdf[tempdf.goal == 'categorydraw'].feature_ind.values], \\\n",
    "                        inst_fc6[tempdf[tempdf.goal == 'instancedraw'].feature_ind.values]), axis = 0).mean(axis=0))\n",
    "    mean_category_features_text_cat.append(cats_fc6[tempdf[tempdf.goal == \\\n",
    "                                                           'categorydraw'].feature_ind.values].mean(axis=0))\n",
    "    mean_category_features_text_inst.append(inst_fc6[tempdf[tempdf.goal == \\\n",
    "                                                            'instancedraw'].feature_ind.values].mean(axis=0))\n",
    "    \n",
    "mean_category_features_text = pd.DataFrame(mean_category_features_text)\n",
    "mean_category_features_text['category'] = K2.category.unique()\n",
    "mean_category_features_text['condition'] = 'text'\n",
    "\n",
    "mean_category_features_text_cat = pd.DataFrame(mean_category_features_text_cat)\n",
    "mean_category_features_text_cat['category'] = K2.category.unique()\n",
    "mean_category_features_text_cat['condition'] = 'text'\n",
    "\n",
    "mean_category_features_text_inst = pd.DataFrame(mean_category_features_text_inst)\n",
    "mean_category_features_text_inst['category'] = K2.category.unique()\n",
    "mean_category_features_text_inst['condition'] = 'text'\n",
    "\n",
    "\n",
    "mean_category_features = pd.concat([mean_category_features_photo, mean_category_features_text], ignore_index=True)\n",
    "mean_category_features.index = mean_category_features.category + '_' + mean_category_features.condition\n",
    "mean_category_features = mean_category_features.drop(columns=['condition', 'category'])\n",
    "\n",
    "mean_category_features_cat = pd.concat([mean_category_features_photo, mean_category_features_text_cat]\\\n",
    "                                            , ignore_index=True)\n",
    "mean_category_features_cat.index = mean_category_features_cat.category + '_' + \\\n",
    "mean_category_features_cat.condition\n",
    "mean_category_features_cat = mean_category_features_cat.drop(columns=['condition', 'category'])\n",
    "\n",
    "mean_category_features_inst = pd.concat([mean_category_features_photo, mean_category_features_text_inst], ignore_index=True)\n",
    "mean_category_features_inst.index = mean_category_features_inst.category + '_' + mean_category_features_inst.condition\n",
    "mean_category_features_inst = mean_category_features_inst.drop(columns=['condition', 'category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "between_condition_RDM = pd.DataFrame(squareform(pdist(mean_category_features.values)), \\\n",
    "            columns = mean_category_features.index, index = mean_category_features.index)\n",
    "\n",
    "plt.figure(figsize=(18,25))\n",
    "sns.heatmap(between_condition_RDM,cbar_kws={'orientation':'horizontal'})\n",
    "plt.xlabel('category-condition pairs'), plt.ylabel('category-condition pairs')\n",
    "plt.title(f'Correlation coefficient of mean feature vectors of each category-condition pair (fc6)', fontsize=26);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "between_condition_RDM = pd.DataFrame(np.corrcoef(mean_category_features.values), \\\n",
    "            columns = mean_category_features.index, index = mean_category_features.index)\n",
    "\n",
    "plt.figure(figsize=(18,25))\n",
    "sns.heatmap(between_condition_RDM,cbar_kws={'orientation':'horizontal'})\n",
    "plt.xlabel('category-condition pairs'), plt.ylabel('category-condition pairs')\n",
    "plt.title(f'Correlation coefficient of mean feature vectors of each category-condition pair (fc6)', fontsize=26);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "between_condition_RDM_cat = pd.DataFrame(np.corrcoef(mean_category_features_cat.values), \\\n",
    "            columns = mean_category_features_cat.index, index = mean_category_features_cat.index)\n",
    "\n",
    "plt.figure(figsize=(18,25))\n",
    "sns.heatmap(between_condition_RDM_cat,cbar_kws={'orientation':'horizontal'})\n",
    "plt.xlabel('category-condition pairs'), plt.ylabel('category-condition pairs')\n",
    "plt.title(f'Pairwise euclidean distance of mean feature vectors of each category-condition pair', fontsize=26);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "between_condition_RDM_inst = pd.DataFrame(np.corrcoef(mean_category_features_inst.values), \\\n",
    "            columns = mean_category_features_inst.index, index = mean_category_features_inst.index)\n",
    "\n",
    "plt.figure(figsize=(18,25))\n",
    "sns.heatmap(between_condition_RDM_inst,cbar_kws={'orientation':'horizontal'})\n",
    "plt.xlabel('category-condition pairs'), plt.ylabel('category-condition pairs')\n",
    "plt.title(f'Pairwise correlation coefficients of mean feature vectors of each category-condition pair', fontsize=26);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "between_condition_RDM_diff = np.abs(between_condition_RDM_cat - between_condition_RDM_inst)\n",
    "plt.figure(figsize=(18,25))\n",
    "sns.heatmap(between_condition_RDM_diff,cbar_kws={'orientation':'horizontal'})\n",
    "plt.xlabel('category-condition pairs'), plt.ylabel('category-condition pairs')\n",
    "plt.title(f'Difference between category and instance feature representations', fontsize=26);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ttest_ind(between_condition_RDM_cat.iloc[32:,32:].values.flatten(), \\\n",
    "          between_condition_RDM_inst.iloc[32:,32:].values.flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_text_corrs = get_correlation_distances(cat_text_fc6_mean)\n",
    "inst_text_corrs = get_correlation_distances(inst_text_fc6_mean)\n",
    "#cat_photo_corrs = get_correlation_distances(cat_photo_fc6_mean)\n",
    "#inst_photo_corrs = get_correlation_distances(inst_photo_fc6_mean)\n",
    "\n",
    "photo_cues_corrs = get_correlation_distances(photo_cues_fc6_mean)\n",
    "sketchy_sketches_corrs = get_correlation_distances(sketchy_sketches_fc6_mean)\n",
    "\n",
    "# verify everything is the same size\n",
    "assert(len(cat_text_corrs) == len(inst_text_corrs)) # == len(cat_photo_corrs) == len(inst_photo_corrs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### More RDM analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have 4 different feature representations, one for each experiments\n",
    "cat_text_fc6 = np.load(os.path.join(feature_dir, f'FEATURES_FC6_sketch_no-channel-norm_categorydraw-text.npy'))\n",
    "inst_text_fc6 = np.load(os.path.join(feature_dir, f'FEATURES_FC6_sketch_no-channel-norm_instancedraw-text.npy'))\n",
    "#cat_photo_fc6 = np.load(os.path.join(feature_dir, f'FEATURES_FC6_sketch_no-channel-norm_categorydraw-photo.npy'))\n",
    "#inst_photo_fc6 = np.load(os.path.join(feature_dir, f'FEATURES_FC6_sketch_no-channel-norm_instancedraw-photo.npy'))\n",
    "\n",
    "photo_cues_fc6 = np.load(os.path.join(feature_dir, f'FEATURES_FC6_sketch_no-channel-norm_photodraw32_stims.npy'))\n",
    "sketchy_sketches_fc6 = np.load(os.path.join(feature_dir, f'FEATURES_FC6_sketch_no-channel-norm_sketchy_sketches.npy'))\n",
    "\n",
    "\n",
    "photo_cues_meta = pd.read_csv(os.path.join(feature_dir, f'METADATA_sketch_photodraw32_stims.csv'))\n",
    "sketchy_sketches_meta = pd.read_csv(os.path.join(feature_dir, 'METADATA_sketch_sketchy_sketches.csv'))\n",
    "\n",
    "photo_cues_meta = photo_cues_meta.rename(columns={'sketch_id': 'photo_id'})\n",
    "sketchy_sketches_meta = sketchy_sketches_meta.rename(columns={'sketch_id': 'photo_id'})\n",
    "\n",
    "photo_cues_meta['category'] = photo_cues_meta.photo_id.str.split('\\\\',expand=True).iloc[:,1]\\\n",
    "                                                       .str.rsplit('_', 2, expand=True).iloc[:,0]\n",
    "\n",
    "photo_cues_meta['id'] = photo_cues_meta.photo_id.str.split('\\\\',expand=True).iloc[:,1]\\\n",
    "                                                 .str.rsplit('_', 2, expand=True)[[1,2]].agg('_'.join, axis=1)\n",
    "\n",
    "                \n",
    "photo_cues_meta = photo_cues_meta.rename(columns={\"sketch_feature_ind\": \"feature_ind\"})\n",
    "\n",
    "sketchy_sketches_meta['category'] = sketchy_sketches_meta.photo_id.str.split('\\\\',expand=True).iloc[:,1]\\\n",
    "                                                                   .str.rsplit('_', 2, expand=True).iloc[:,0]\n",
    "\n",
    "sketchy_sketches_meta['id'] = sketchy_sketches_meta.photo_id.str.split('\\\\',expand=True).iloc[:,1]\\\n",
    "                                                             .str.rsplit('_', 2, expand=True)[[1,2]].agg('_'.join, axis=1)\n",
    "\n",
    "sketchy_sketches_meta[['id', 'sketchNum']] = sketchy_sketches_meta.id.str.split('-', expand=True)\n",
    "sketchy_sketches_meta = sketchy_sketches_meta.rename(columns={\"sketch_feature_ind\": \"feature_ind\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_feature_vectors(metadata, features, groupby_cat = 'category'):\n",
    "    g = metadata.groupby(groupby_cat)\n",
    "    g = g.apply(lambda cat: features[cat.feature_ind.values].mean(axis=0))\n",
    "    return g.index.values, np.stack(list(g), axis=0)\n",
    "\n",
    "def get_correlation_distances(mean_features, upper = True, metric = \"euclidean\"):\n",
    "    corrs = squareform(pdist(mean_features, metric = metric))\n",
    "    #corrs = stats.spearmanr(mean_features, axis=1)[0]\n",
    "                                        \n",
    "    if upper == True:\n",
    "        return corrs[np.triu_indices(len(corrs), 1)]\n",
    "    else:\n",
    "        return corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we get the mean feature representations for each category for each of the 4 experiments:\n",
    "c1, cat_text_fc6_mean = get_mean_feature_vectors(K_cat_text, cat_text_fc6)\n",
    "c2, inst_text_fc6_mean = get_mean_feature_vectors(K_inst_text, inst_text_fc6)\n",
    "#c3, cat_photo_fc6_mean = get_mean_feature_vectors(K_cat_photo, cat_photo_fc6)\n",
    "#c4, inst_photo_fc6_mean = get_mean_feature_vectors(K_ins_photo, inst_photo_fc6)\n",
    "\n",
    "c5, photo_cues_fc6_mean = get_mean_feature_vectors(photo_cues_meta, photo_cues_fc6)\n",
    "c6, sketchy_sketches_fc6_mean = get_mean_feature_vectors(sketchy_sketches_meta, sketchy_sketches_fc6)\n",
    "\n",
    "# verify feature vectors are in the same order\n",
    "assert all([all(i == j) for i,j in combinations([c1, c2, c5, c6], 2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# note: we can subset just the sketch ids used in photodraw2x2 experiments as a placeholder for instancedraw-photo\n",
    "inst_photo_meta =  sketchy_sketches_meta[sketchy_sketches_meta.id.isin(photo_cues_meta.id)]\n",
    "inst_photo_fc6 =  sketchy_sketches_fc6[inst_photo_meta.feature_ind]\n",
    "inst_photo_meta.loc[:, 'feature_ind'] = list(range(len(inst_photo_meta)))\n",
    "c4, inst_photo_fc6_mean = get_mean_feature_vectors(inst_photo_meta, inst_photo_fc6)\n",
    "inst_photo_corrs = get_correlation_distances(inst_photo_fc6_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# note: we can subset just the sketch ids used in photodraw2x2 experiments as a placeholder for instancedraw-photo\n",
    "inst_photo_meta =  sketchy_sketches_meta[sketchy_sketches_meta.id.isin(photo_cues_meta.id)]\n",
    "inst_photo_fc6 =  sketchy_sketches_fc6[inst_photo_meta.feature_ind]\n",
    "inst_photo_meta.loc[:, 'feature_ind'] = list(range(len(inst_photo_meta)))\n",
    "c4, inst_photo_fc6_mean = get_mean_feature_vectors(inst_photo_meta, inst_photo_fc6)\n",
    "inst_photo_corrs = get_correlation_distances(inst_photo_fc6_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(stats.spearmanr([cat_text_corrs, inst_text_corrs, inst_photo_corrs,\\\n",
    "                       photo_cues_corrs, sketchy_sketches_corrs], axis=1)[0])\n",
    "\n",
    "print(stats.spearmanr([cat_text_corrs, inst_text_corrs, inst_photo_corrs,\\\n",
    "                       photo_cues_corrs, sketchy_sketches_corrs], axis=1)[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(1 - stats.spearmanr([cat_text_corrs, inst_text_corrs, inst_photo_corrs,\\\n",
    "                       photo_cues_corrs, sketchy_sketches_corrs], axis=1)[0], \n",
    "           square = True, xticklabels=['cat_text', 'inst_text', 'inst_photo', 'photo_cues', 'sketchy_sketches'],\n",
    "                          yticklabels=['cat_text', 'inst_text', 'inst_photo', 'photo_cues', 'sketchy_sketches'])\n",
    "plt.title('Distance matrix of various RDMs (testing)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c8, id_feature_vectors = get_mean_feature_vectors(inst_photo_meta, inst_photo_fc6, 'id')\n",
    "id_feature_vectors_corrs = get_correlation_distances(id_feature_vectors, upper = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(id_feature_vectors_corrs, square = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get typicality ratings\n",
    "norming_data = pd.read_csv(os.path.join(csv_dir, 'photodraw_sketchy32_typicality_ratings.csv'))\n",
    "norming_data = norming_data[(norming_data.catch_trial == False) &\n",
    "                            (norming_data.repeat_offender == False) & \n",
    "                            (norming_data.failed_catches == False) & \n",
    "                            (norming_data.tooDissimilar == False)]\n",
    "\n",
    "norming_data['sketchy_id'] = norming_data.img_id.str.rsplit('/', 1, expand = True).iloc[:,1]\\\n",
    "                                                .str.rsplit('.', 1, expand = True).iloc[:,0]\\\n",
    "                                                .str.split('_',expand=True)[[0,1]].agg('_'.join, axis = 1)\n",
    "norming_data = norming_data.groupby(['category','sketchy_id']).enumerated_ratings.describe().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_ids = norming_data.sort_values(by=['category', 'mean', '50%']).sketchy_id.values\n",
    "photo_ids = dict(zip(c8, range(len(c8))))\n",
    "rearrangement = [photo_ids[sid] for sid in sorted_ids] \n",
    "id_feature_vectors_corrs_arr = get_correlation_distances(id_feature_vectors[rearrangement], upper = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.heatmap(id_feature_vectors_corrs_arr, square = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does photo-cue typicality relate to sketch recognizability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = pd.read_csv(os.path.join(csv_dir, 'photodraw_sketchy32_typicality_ratings.csv'))\n",
    "\n",
    "R = R[(R.repeat_offender == False) & (R.tooDissimilar == False) & (R.failed_catches == False) & (R.catch_trial == False)]\n",
    "R['imageURL'] = R.img_id.str.split('/', expand=True).iloc[:,-1].str.split('_', expand=True)\\\n",
    "                                                               .iloc[:,:2].agg('_'.join, axis=1)\n",
    "\n",
    "rara = pd.DataFrame(R.groupby(['imageURL', 'category']).enumerated_ratings.mean()).reset_index()  \n",
    "rara['isTypical'] = rara.apply(lambda row: row.enumerated_ratings >= \\\n",
    "                               rara[rara.category == row.category].enumerated_ratings.median(), axis = 1)\n",
    "K['isTypical'] = K.imageURL.map(dict(zip(rara.imageURL, rara.isTypical)))\n",
    "\n",
    "cat_ratings_map = R.groupby('category').enumerated_ratings.mean().to_dict()\n",
    "inst_ratings_map = R.groupby('imageURL').enumerated_ratings.mean().to_dict()\n",
    "K['cat_typicality'] = K.category.map(cat_ratings_map)\n",
    "K['inst_typicality'] = K.imageURL.map(inst_ratings_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array,value):\n",
    "    idx = np.searchsorted(array, value, side=\"left\")\n",
    "    if idx > 0 and (idx == len(array) or math.fabs(value - array[idx-1]) < math.fabs(value - array[idx])):\n",
    "        return idx - 1\n",
    "    else:\n",
    "        return idx\n",
    "    \n",
    "R = pd.read_csv(os.path.join(csv_dir, 'photodraw_sketchy32_typicality_ratings.csv'))\n",
    "\n",
    "R = R[(R.repeat_offender == False) & (R.tooDissimilar == False) & (R.failed_catches == False) & (R.catch_trial == False)]\n",
    "R['imageURL'] = R.img_id.str.split('/', expand=True).iloc[:,-1].str.split('_', expand=True)\\\n",
    "                                                               .iloc[:,:2].agg('_'.join, axis=1)\n",
    "\n",
    "rara = pd.DataFrame(R.groupby(['imageURL', 'category']).enumerated_ratings.mean()).reset_index()  \n",
    "rara['isTypical'] = rara.apply(lambda row: row.enumerated_ratings >= \\\n",
    "                               rara[rara.category == row.category].enumerated_ratings.median(), axis = 1)\n",
    "rara['enumerated_ratings'] = rara['enumerated_ratings'] + 0.001 * (np.random.rand(len(rara)) - 0.5)\n",
    "rara['decile'] =  rara.groupby(['category'])['enumerated_ratings'].transform(\n",
    "                     lambda x: pd.qcut(x, 8, labels=range(8)))\n",
    "\n",
    "#rara['decile'] = rara.apply(lambda row: find_nearest(pd.cut(rara[rara.category == row.category].enumerated_ratings, \\\n",
    "#                                            9, labels = range(9), retbins=True)[-1], row.enumerated_ratings), axis = 1)\n",
    "K['decile'] = K.imageURL.map(dict(zip(rara.imageURL, rara.decile)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style('ticks')\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "\n",
    "plt.figure(figsize=(3,8))\n",
    "sns.lineplot(data = K[(K.isOutlier == False) & (K.condition == 'photo')], \\\n",
    "            x = 'decile', y = 'prob_true_predict_fc6_logodds', hue = 'goal', linewidth = 4,\n",
    "            palette=[\"#C93312\", \"#899DA4\"], legend=False)\n",
    "plt.ylabel('')\n",
    "plt.xlabel('');\n",
    "#plt.savefig(os.path.join(plot_dir, 'photodraw2x2_typicality_logodds_lineplot.pdf'), bbox_inches = 'tight', transparent=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Effect of typicality on recognizability by goal\n",
    "K[(K['isOutlier'] == False) & (K.condition == 'photo')].groupby(['goal','isTypical'])['prob_true_predict_fc6'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = sns.catplot(\n",
    "    data=K[(K['isOutlier'] == False) & (K.condition == 'photo')], kind=\"bar\",\n",
    "    x=\"goal\", y=\"prob_true_predict_fc6_logodds\", hue=\"isTypical\", palette=\"dark\", alpha=.7, height=5\n",
    ")\n",
    "g.despine(left=True)\n",
    "g.set_axis_labels(\"isTypical\", \"probability (logodds)\")\n",
    "plt.title('Probability of correct classification (logodds)');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Effect of ImageNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('imagenet1000_labels.txt') as f: \n",
    "    imagenet_labels = f.read() \n",
    "imagenet_labels = ast.literal_eval(imagenet_labels) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.DataFrame(inImagenet.items())\n",
    "x[x[1] == False][0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inImagenet = dict([[j, sum([j in i for i in list(imagenet_labels.values())]) != 0] for j in K.category.unique()])\n",
    "K['in_imagenet'] = K.category.map(inImagenet)\n",
    "\n",
    "K.groupby('in_imagenet')[['prob_true_predict_fc6', 'true_predict_fc6', 'prob_true_predict_instance',\\\n",
    "                          'true_predict_instance']].apply(np.mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "sns.barplot(data = K, x = 'experiment', y = 'prob_true_predict_fc6', hue = 'in_imagenet')\n",
    "plt.legend(title = 'in_imagenet', bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sns.barplot(data = K, x = 'in_imagenet', y = 'prob_true_predict_fc6', hue = 'condition')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "np.mean([sum([j == i for i in list(imagenet_labels.values())]) != 0 for j in K.category.unique()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean([sum([j in i for i in list(imagenet_labels.values())]) != 0 for j in K.category.unique()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic demographics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# demographic information for photodraw2x2\n",
    "K['participantSex'].value_counts() / 32\n",
    "K.inputDevice.value_counts() / 32\n",
    "K.participantAge.value_counts() / 32\n",
    "\n",
    "# mean age of participants, removing outlier datapoints\n",
    "knew = K[pd.to_numeric(K.participantAge, errors='coerce').notnull()]  \n",
    "knew['participantAge'] = knew.participantAge.astype(int)\n",
    "(2021 - knew[(knew.participantAge > 1930) & (knew.participantAge < 2020)\n",
    "            ].groupby('gameID').participantAge.first().values).mean()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
